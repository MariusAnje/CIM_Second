{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.8 64-bit"
  },
  "interpreter": {
   "hash": "f09c96bd4e15584f4d9e293bfe8df79352bc2ff8b62e2c337721549e56de9c71"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import autograd\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torch import optim\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from models import SCrossEntropyLoss, OCrossEntropyLoss, SMLP3, SMLP4\n",
    "from Functions import SCrossEntropyLossFunction\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval():\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    model.clear_noise()\n",
    "    model.clear_mask()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            images = images.view(-1, 784)\n",
    "            outputs = model(images)\n",
    "            predictions = outputs.argmax(dim=1)\n",
    "            correction = predictions == labels\n",
    "            correct += correction.sum()\n",
    "            total += len(correction)\n",
    "    return (correct/total).item()\n",
    "\n",
    "def Seval(is_clear_mask=True):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        model.clear_noise()\n",
    "        if is_clear_mask:\n",
    "            model.clear_mask()\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            images = images.view(-1, 784)\n",
    "            outputs = model(images)\n",
    "            predictions = outputs[0].argmax(dim=1)\n",
    "            correction = predictions == labels\n",
    "            correct += correction.sum()\n",
    "            total += len(correction)\n",
    "    return (correct/total).item()\n",
    "\n",
    "def Seval_noise(var, is_clear_mask=True):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    model.clear_noise()\n",
    "    if is_clear_mask:\n",
    "        model.clear_mask()\n",
    "    with torch.no_grad():\n",
    "        model.set_noise(var)\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            images = images.view(-1, 784)\n",
    "            outputs = model(images)\n",
    "            predictions = outputs[0].argmax(dim=1)\n",
    "            correction = predictions == labels\n",
    "            correct += correction.sum()\n",
    "            total += len(correction)\n",
    "    return (correct/total).item()\n",
    "\n",
    "def STrain(epochs):\n",
    "    best_acc = 0.0\n",
    "    for i in range(epochs):\n",
    "        running_loss = 0.\n",
    "        running_l = 0.\n",
    "        for images, labels in tqdm(trainloader):\n",
    "            optimizer.zero_grad()\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            images = images.view(-1, 784)\n",
    "            outputs, outputsS = model(images)\n",
    "            loss = criteria(outputs, outputsS,labels)\n",
    "            loss.backward()\n",
    "            l = loss + model.fetch_H_grad()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            running_l += l.item()\n",
    "        test_acc = Seval()\n",
    "        if test_acc > best_acc:\n",
    "            best_acc = test_acc\n",
    "            torch.save(model.state_dict(), \"tmp_best.pt\")\n",
    "        print(f\"epoch: {i:-3d}, test acc: {test_acc:.4f}, loss: {running_loss / len(trainloader):.4f}, s: {(running_l - running_loss) / len(trainloader):-5.4f}\")\n",
    "\n",
    "def GetSecond():\n",
    "    running_loss = 0.\n",
    "    running_l = 0.\n",
    "    optimizer.zero_grad()\n",
    "    loss_function = SCrossEntropyLoss()\n",
    "    for images, labels in tqdm(trainloader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        images = images.view(-1, 784)\n",
    "        outputs, outputsS = model(images)\n",
    "        loss = loss_function(outputs, outputsS,labels)\n",
    "        loss.backward()\n",
    "\n",
    "\n",
    "device = torch.device(args.device if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "BS = 128\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='~/Private/data', train=True,\n",
    "                                        download=False, transform=transforms.ToTensor())\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BS,\n",
    "                                        shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='~/Private/data', train=False,\n",
    "                                    download=False, transform=transforms.ToTensor())\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BS,\n",
    "                                            shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=469.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b3ff5a4ed0e24baeb6e45036b3725cf5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "epoch:   0, test acc: 0.9400, loss: 0.3093, s: 0.0000\n"
     ]
    }
   ],
   "source": [
    "model = SMLP3()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, [20])\n",
    "# criteria = SCrossEntropyLoss()\n",
    "criteria = OCrossEntropyLoss()\n",
    "model.to_first()\n",
    "STrain(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=469.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f170b3e6694b48fda5ceeab58f99c74e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ntensor(369.9479)\ntensor(23018.9043)\ntensor(38573.5938)\n"
     ]
    }
   ],
   "source": [
    "model.to_second()\n",
    "GetSecond()\n",
    "print(model.fc1.weightH.grad.max())\n",
    "print(model.fc2.weightH.grad.max())\n",
    "print(model.fc3.weightH.grad.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.858299970626831"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "model.set_mask(10000,\"th\")\n",
    "Seval(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=469.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b223be1b096d4284ade61033200c42f9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(13375.1816)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "GetSecond()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}